# AUTOGENERATED! DO NOT EDIT! File to edit: ../02_laziness.ipynb.

# %% auto 0
__all__ = ['curvature']

# %% ../02_laziness.ipynb 3
import numpy as np
def curvature(P, diffusion_powers=8, aperture = 20, smoothing=1, verbose = False, return_density = False, dynamically_adjusting_neighborhood = False, precomputed_powered_P = None, non_lazy_diffusion=False, avg_transition_probability=True, use_min_threshold = False):
    """Diffusion Laziness Curvature
    Estimates curvature by measuring the amount of mass remaining within an initial neighborhood after t steps of diffusion. Akin to measuring the laziness of a random walk after t steps.

    Parameters
    ----------
    P : n x n ndarray
        The diffusion matrix of the graph
    diffusion_powers : int, optional
        Number of steps of diffusion to take before measuring the laziness, by default 8
    aperture : int, optional
        The size of the initial neighborhood, from which the percentage of mass remaining in this neighborhood is calculated, by default 20
    smoothing : int, optional
        Amount of smoothing to apply. Currently works by multiplying the raw laziness values with the diffusion operator, as a kind of iterated weighted averaging; by default 1
    verbose : bool, optional
        Print diagnostics, by default False
    return_density : bool, optional
        Return the number of neighbors each point shares, by default False
    dynamically_adjusting_neighborhood : bool, optional
        Whether to give each point the same initial neighborhood size, by default False
    precomputed_powered_P : ndarray, optional
        Optionally pass a precomputed powered diffusion operator, to speed up computation, by default None
    avg_transition_probability: bool, default True
        Use the definition of diffusion curvature in which the summed transition probabilities are divided by the total number of points in the aperture neighborhood.
        As a result, gives not the summed "return probability within the neighborhood" but the average return probability to each point in the aperture neighborhood.
        This formulation of diffusion curvature was used in proof given in our NeurIPS 2022 paper.

    Returns
    -------
    length n array
        The laziness curvature values for each point
    """
    # the aperture sets the size of the one-hop neighborhood 
    # the aperture parameter is the average number of neighbors to include, based off of the sorted diffusion values
    # Set thresholds as the kth largest diffusion value, presumed to be held by the kth nearest neighbor.
    thresholds = np.partition(P,-aperture)[:,-aperture]
    # thresholds = np.sort(P)[:,-aperture] 
    if verbose: print(thresholds)
    if dynamically_adjusting_neighborhood:
        P_thresholded = (P >= thresholds[:,None]).astype(int)
    else:
        if use_min_threshold:
            P_threshold = np.min(thresholds)
        else:
            P_threshold = np.mean(thresholds) # TODO could also use min
        P_thresholded = (P >= P_threshold).astype(int)
        if verbose: print("Derived threshold ",P_threshold)

    if verbose: print(np.sum(P_thresholded,axis=1))
    if verbose: print("Performing matrix powers...")
    
    if precomputed_powered_P is not None:
        P_powered = precomputed_powered_P
    elif non_lazy_diffusion:
        print("Removing self-diffusion")
        P_zero_diagonal = (np.ones_like(P) - np.diag(np.ones(len(P))))*P
        D = np.diag(1/np.sum(P_zero_diagonal,axis=0))
        P = D @ P_zero_diagonal
        P_powered = np.linalg.matrix_power(P,diffusion_powers)
    else:
        P_powered = np.linalg.matrix_power(P,diffusion_powers)
    # take the diffusion probs of the neighborhood
    near_neighbors_only = P_powered * P_thresholded
    laziness_aggregate = np.sum(near_neighbors_only,axis=1)
    if avg_transition_probability:
        ones_matrix = np.ones_like(P_thresholded)
        ones_remaining = ones_matrix * P_thresholded
        local_density = np.sum(ones_remaining,axis=1)
        if verbose: print("local density",local_density)
        # divide by the number of neighbors diffused to
        # TODO: In case of isolated points, replace local density of 0 with 1. THe laziness will evaluate to zero.
        local_density[local_density==0]=1
        laziness_aggregate = laziness_aggregate / local_density
    laziness = laziness_aggregate
    if smoothing: # TODO there are probably more intelligent ways to do this smoothing
        # Local averaging to counter the effects local density
        if verbose: print("Applying smoothing...")
        smoothing_P_powered = np.linalg.matrix_power(P,smoothing)
        average_laziness = smoothing_P_powered @ laziness_aggregate[:,None]
        average_laziness = average_laziness.squeeze()
        laziness = average_laziness
    if return_density:
        # compute sums of neighbors taken into consideration
        ones_matrix = np.ones_like(P_thresholded)
        ones_remaining = ones_matrix * P_thresholded
        local_density = np.sum(ones_remaining,axis=1)
        return laziness, local_density
    return laziness
